{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_and_evaluate_AlexSGD_5fold(data_path, batch_size=16, learning_rate=0.01, num_epochs=8, num_folds=5):\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "    # Initialise K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    # Initialise containers for aggregated results\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Start cross-validation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        print(f'FOLD {fold+1}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of indices for train and validation\n",
    "        train_subsampler = Subset(dataset, train_ids)\n",
    "        val_subsampler = Subset(dataset, val_ids)\n",
    "\n",
    "        # Define data loaders for training and validation\n",
    "        train_loader = DataLoader(dataset=train_subsampler, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(dataset=val_subsampler, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Load a pre-trained AlexNet model\n",
    "        model = models.alexnet(pretrained=True)\n",
    "\n",
    "        # Modify the final layer to match the number of classes\n",
    "        num_classes = len(dataset.classes)  # Automatically get the number of classes\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "        # Move model to GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate and print the final aggregated classification report\n",
    "    classes = dataset.classes  # Automatically get the class names from the dataset\n",
    "    final_report = classification_report(all_labels, all_preds, target_names=classes, output_dict=True)\n",
    "    \n",
    "    print('--------------------------------')\n",
    "    print('Final Cross-Validation Results:')\n",
    "    print(classification_report(all_labels, all_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def train_and_evaluate_AlexAdaGrad_5fold(data_path, batch_size=16, learning_rate=0.001, num_epochs=8, num_folds=5):\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "    # Initialize K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    # Initialise containers for aggregated results\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Start cross-validation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        print(f'FOLD {fold+1}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of indices for train and validation\n",
    "        train_subsampler = Subset(dataset, train_ids)\n",
    "        val_subsampler = Subset(dataset, val_ids)\n",
    "\n",
    "        # Define data loaders for training and validation\n",
    "        train_loader = DataLoader(dataset=train_subsampler, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(dataset=val_subsampler, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Load a pre-trained AlexNet model\n",
    "        model = models.alexnet(pretrained=True)\n",
    "\n",
    "        # Modify the final layer to match the number of classes\n",
    "        num_classes = len(dataset.classes)  # Automatically get the number of classes\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "        # Move model to GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)  # Updated to AdaGrad optimizer\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate and print the final aggregated classification report\n",
    "    classes = dataset.classes  # Automatically get the class names from the dataset\n",
    "    final_report = classification_report(all_labels, all_preds, target_names=classes, output_dict=True)\n",
    "    \n",
    "    print('--------------------------------')\n",
    "    print('Final Cross-Validation Results:')\n",
    "    print(classification_report(all_labels, all_preds, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def train_and_evaluate_AlexAdam_5fold(data_path, batch_size=16, learning_rate=0.0001, num_epochs=8, num_folds=5):\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "    # Initialize K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    # Initialize containers for aggregated results\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Start cross-validation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "        print(f'FOLD {fold+1}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of indices for train and validation\n",
    "        train_subsampler = Subset(dataset, train_ids)\n",
    "        val_subsampler = Subset(dataset, val_ids)\n",
    "\n",
    "        # Define data loaders for training and validation\n",
    "        train_loader = DataLoader(dataset=train_subsampler, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(dataset=val_subsampler, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Load a pre-trained AlexNet model\n",
    "        model = models.alexnet(pretrained=True)\n",
    "\n",
    "        # Modify the final layer to match the number of classes\n",
    "        num_classes = len(dataset.classes)  # Automatically get the number of classes\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "        # Move model to GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Updated to Adam optimizer\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate and print the final aggregated classification report\n",
    "    classes = dataset.classes  # Automatically get the class names from the dataset\n",
    "    final_report = classification_report(all_labels, all_preds, target_names=classes, output_dict=True)\n",
    "    \n",
    "    print('--------------------------------')\n",
    "    print('Final Cross-Validation Results:')\n",
    "    print(classification_report(all_labels, all_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.3486\n",
      "Epoch [2/8], Loss: 0.7968\n",
      "Epoch [3/8], Loss: 0.6561\n",
      "Epoch [4/8], Loss: 0.4752\n",
      "Epoch [5/8], Loss: 0.3916\n",
      "Epoch [6/8], Loss: 0.3535\n",
      "Epoch [7/8], Loss: 0.3254\n",
      "Epoch [8/8], Loss: 0.2740\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.4120\n",
      "Epoch [2/8], Loss: 0.8302\n",
      "Epoch [3/8], Loss: 0.6503\n",
      "Epoch [4/8], Loss: 0.5090\n",
      "Epoch [5/8], Loss: 0.4090\n",
      "Epoch [6/8], Loss: 0.3616\n",
      "Epoch [7/8], Loss: 0.2927\n",
      "Epoch [8/8], Loss: 0.2608\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.3981\n",
      "Epoch [2/8], Loss: 0.9068\n",
      "Epoch [3/8], Loss: 0.6598\n",
      "Epoch [4/8], Loss: 0.5398\n",
      "Epoch [5/8], Loss: 0.4477\n",
      "Epoch [6/8], Loss: 0.3623\n",
      "Epoch [7/8], Loss: 0.3301\n",
      "Epoch [8/8], Loss: 0.3284\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.3934\n",
      "Epoch [2/8], Loss: 0.8720\n",
      "Epoch [3/8], Loss: 0.6619\n",
      "Epoch [4/8], Loss: 0.5494\n",
      "Epoch [5/8], Loss: 0.4467\n",
      "Epoch [6/8], Loss: 0.3625\n",
      "Epoch [7/8], Loss: 0.3229\n",
      "Epoch [8/8], Loss: 0.2987\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.3841\n",
      "Epoch [2/8], Loss: 0.8395\n",
      "Epoch [3/8], Loss: 0.6786\n",
      "Epoch [4/8], Loss: 0.5504\n",
      "Epoch [5/8], Loss: 0.4394\n",
      "Epoch [6/8], Loss: 0.4054\n",
      "Epoch [7/8], Loss: 0.3290\n",
      "Epoch [8/8], Loss: 0.2997\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.85      0.90      0.88       298\n",
      "       blank       0.91      0.94      0.92       300\n",
      "  haast kiwi       0.82      0.88      0.85       270\n",
      "        kaka       0.83      0.80      0.81       282\n",
      "         kea       0.90      0.93      0.92       226\n",
      "    morepork       0.95      0.94      0.94       261\n",
      "  other kiwi       0.87      0.79      0.83       308\n",
      "    shelduck       0.97      0.97      0.97       288\n",
      "    swamphen       0.93      0.88      0.90       201\n",
      "\n",
      "    accuracy                           0.89      2434\n",
      "   macro avg       0.89      0.89      0.89      2434\n",
      "weighted avg       0.89      0.89      0.89      2434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\44778\\OneDrive\\Desktop\\UWE_Docs\\7. Dissertation\\CNN Data Files\\Old_Data\\Viridis\\Mel (Balanced)\"\n",
    "train_and_evaluate_AlexSGD_5fold(data_path, batch_size=16, learning_rate=0.01, num_epochs=8, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.3716\n",
      "Epoch [2/8], Loss: 0.7589\n",
      "Epoch [3/8], Loss: 0.5179\n",
      "Epoch [4/8], Loss: 0.3721\n",
      "Epoch [5/8], Loss: 0.2651\n",
      "Epoch [6/8], Loss: 0.2271\n",
      "Epoch [7/8], Loss: 0.1808\n",
      "Epoch [8/8], Loss: 0.1369\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.5008\n",
      "Epoch [2/8], Loss: 0.8983\n",
      "Epoch [3/8], Loss: 0.6204\n",
      "Epoch [4/8], Loss: 0.4703\n",
      "Epoch [5/8], Loss: 0.3658\n",
      "Epoch [6/8], Loss: 0.2878\n",
      "Epoch [7/8], Loss: 0.2286\n",
      "Epoch [8/8], Loss: 0.1949\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.4042\n",
      "Epoch [2/8], Loss: 0.7244\n",
      "Epoch [3/8], Loss: 0.4859\n",
      "Epoch [4/8], Loss: 0.3617\n",
      "Epoch [5/8], Loss: 0.2558\n",
      "Epoch [6/8], Loss: 0.2100\n",
      "Epoch [7/8], Loss: 0.1447\n",
      "Epoch [8/8], Loss: 0.1334\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.4602\n",
      "Epoch [2/8], Loss: 0.8419\n",
      "Epoch [3/8], Loss: 0.5124\n",
      "Epoch [4/8], Loss: 0.3456\n",
      "Epoch [5/8], Loss: 0.2514\n",
      "Epoch [6/8], Loss: 0.1997\n",
      "Epoch [7/8], Loss: 0.1442\n",
      "Epoch [8/8], Loss: 0.1245\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.5624\n",
      "Epoch [2/8], Loss: 0.9159\n",
      "Epoch [3/8], Loss: 0.5735\n",
      "Epoch [4/8], Loss: 0.3973\n",
      "Epoch [5/8], Loss: 0.2630\n",
      "Epoch [6/8], Loss: 0.2164\n",
      "Epoch [7/8], Loss: 0.1682\n",
      "Epoch [8/8], Loss: 0.1335\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.90      0.90      0.90       298\n",
      "       blank       0.94      0.95      0.95       300\n",
      "  haast kiwi       0.86      0.94      0.90       270\n",
      "        kaka       0.91      0.83      0.87       282\n",
      "         kea       0.96      0.92      0.94       226\n",
      "    morepork       0.92      0.97      0.95       261\n",
      "  other kiwi       0.88      0.80      0.83       308\n",
      "    shelduck       0.95      0.99      0.97       288\n",
      "    swamphen       0.92      0.96      0.94       201\n",
      "\n",
      "    accuracy                           0.91      2434\n",
      "   macro avg       0.91      0.92      0.92      2434\n",
      "weighted avg       0.91      0.91      0.91      2434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_AlexAdaGrad_5fold(data_path, batch_size=16, learning_rate=0.001, num_epochs=8, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.0818\n",
      "Epoch [2/8], Loss: 0.5409\n",
      "Epoch [3/8], Loss: 0.3754\n",
      "Epoch [4/8], Loss: 0.2672\n",
      "Epoch [5/8], Loss: 0.2364\n",
      "Epoch [6/8], Loss: 0.2246\n",
      "Epoch [7/8], Loss: 0.2067\n",
      "Epoch [8/8], Loss: 0.1830\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.1479\n",
      "Epoch [2/8], Loss: 0.5722\n",
      "Epoch [3/8], Loss: 0.4221\n",
      "Epoch [4/8], Loss: 0.2767\n",
      "Epoch [5/8], Loss: 0.2514\n",
      "Epoch [6/8], Loss: 0.2192\n",
      "Epoch [7/8], Loss: 0.1878\n",
      "Epoch [8/8], Loss: 0.1610\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.1608\n",
      "Epoch [2/8], Loss: 0.5766\n",
      "Epoch [3/8], Loss: 0.3744\n",
      "Epoch [4/8], Loss: 0.3304\n",
      "Epoch [5/8], Loss: 0.2516\n",
      "Epoch [6/8], Loss: 0.2328\n",
      "Epoch [7/8], Loss: 0.1983\n",
      "Epoch [8/8], Loss: 0.1519\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.1613\n",
      "Epoch [2/8], Loss: 0.5126\n",
      "Epoch [3/8], Loss: 0.3731\n",
      "Epoch [4/8], Loss: 0.2826\n",
      "Epoch [5/8], Loss: 0.2568\n",
      "Epoch [6/8], Loss: 0.1990\n",
      "Epoch [7/8], Loss: 0.1627\n",
      "Epoch [8/8], Loss: 0.1883\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.1872\n",
      "Epoch [2/8], Loss: 0.6066\n",
      "Epoch [3/8], Loss: 0.4083\n",
      "Epoch [4/8], Loss: 0.3201\n",
      "Epoch [5/8], Loss: 0.2811\n",
      "Epoch [6/8], Loss: 0.2034\n",
      "Epoch [7/8], Loss: 0.1756\n",
      "Epoch [8/8], Loss: 0.1718\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.94      0.93      0.93       298\n",
      "       blank       0.93      0.97      0.95       300\n",
      "  haast kiwi       0.85      0.87      0.86       270\n",
      "        kaka       0.88      0.87      0.87       282\n",
      "         kea       0.96      0.95      0.96       226\n",
      "    morepork       1.00      0.94      0.97       261\n",
      "  other kiwi       0.86      0.88      0.87       308\n",
      "    shelduck       0.97      0.94      0.95       288\n",
      "    swamphen       0.93      0.94      0.94       201\n",
      "\n",
      "    accuracy                           0.92      2434\n",
      "   macro avg       0.92      0.92      0.92      2434\n",
      "weighted avg       0.92      0.92      0.92      2434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_AlexAdam_5fold(data_path, batch_size=16, learning_rate=0.0001, num_epochs=8, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.6915\n",
      "Epoch [2/8], Loss: 1.2310\n",
      "Epoch [3/8], Loss: 1.0020\n",
      "Epoch [4/8], Loss: 0.8533\n",
      "Epoch [5/8], Loss: 0.7206\n",
      "Epoch [6/8], Loss: 0.6202\n",
      "Epoch [7/8], Loss: 0.5869\n",
      "Epoch [8/8], Loss: 0.4885\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.6282\n",
      "Epoch [2/8], Loss: 1.2029\n",
      "Epoch [3/8], Loss: 0.9816\n",
      "Epoch [4/8], Loss: 0.7851\n",
      "Epoch [5/8], Loss: 0.7160\n",
      "Epoch [6/8], Loss: 0.5912\n",
      "Epoch [7/8], Loss: 0.5301\n",
      "Epoch [8/8], Loss: 0.5298\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.6842\n",
      "Epoch [2/8], Loss: 1.1767\n",
      "Epoch [3/8], Loss: 0.9681\n",
      "Epoch [4/8], Loss: 0.8318\n",
      "Epoch [5/8], Loss: 0.6745\n",
      "Epoch [6/8], Loss: 0.5706\n",
      "Epoch [7/8], Loss: 0.4724\n",
      "Epoch [8/8], Loss: 0.4109\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.7350\n",
      "Epoch [2/8], Loss: 1.1657\n",
      "Epoch [3/8], Loss: 0.9935\n",
      "Epoch [4/8], Loss: 0.8189\n",
      "Epoch [5/8], Loss: 0.7180\n",
      "Epoch [6/8], Loss: 0.6000\n",
      "Epoch [7/8], Loss: 0.5487\n",
      "Epoch [8/8], Loss: 0.5014\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.6613\n",
      "Epoch [2/8], Loss: 1.1895\n",
      "Epoch [3/8], Loss: 0.9218\n",
      "Epoch [4/8], Loss: 0.8129\n",
      "Epoch [5/8], Loss: 0.6947\n",
      "Epoch [6/8], Loss: 0.6137\n",
      "Epoch [7/8], Loss: 0.4824\n",
      "Epoch [8/8], Loss: 0.4448\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.72      0.88      0.79       149\n",
      "       blank       0.93      0.97      0.95       100\n",
      "  haast kiwi       0.62      0.62      0.62        45\n",
      "        kaka       0.66      0.65      0.66        94\n",
      "         kea       0.87      0.88      0.87       113\n",
      "    morepork       0.89      0.83      0.86        87\n",
      "  other kiwi       0.73      0.62      0.67       154\n",
      "    shelduck       0.94      0.84      0.89        96\n",
      "    swamphen       0.79      0.82      0.80        67\n",
      "\n",
      "    accuracy                           0.79       905\n",
      "   macro avg       0.79      0.79      0.79       905\n",
      "weighted avg       0.80      0.79      0.79       905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\44778\\OneDrive\\Desktop\\UWE_Docs\\7. Dissertation\\CNN Data Files\\Old_Data\\Viridis\\Mel (Raw)\"\n",
    "train_and_evaluate_AlexSGD_5fold(data_path, batch_size=16, learning_rate=0.01, num_epochs=8, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.5565\n",
      "Epoch [2/8], Loss: 1.0696\n",
      "Epoch [3/8], Loss: 0.7827\n",
      "Epoch [4/8], Loss: 0.6351\n",
      "Epoch [5/8], Loss: 0.5398\n",
      "Epoch [6/8], Loss: 0.4567\n",
      "Epoch [7/8], Loss: 0.3799\n",
      "Epoch [8/8], Loss: 0.3115\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.5065\n",
      "Epoch [2/8], Loss: 1.0558\n",
      "Epoch [3/8], Loss: 0.8311\n",
      "Epoch [4/8], Loss: 0.6602\n",
      "Epoch [5/8], Loss: 0.5768\n",
      "Epoch [6/8], Loss: 0.4503\n",
      "Epoch [7/8], Loss: 0.4335\n",
      "Epoch [8/8], Loss: 0.3558\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.5193\n",
      "Epoch [2/8], Loss: 1.0247\n",
      "Epoch [3/8], Loss: 0.7668\n",
      "Epoch [4/8], Loss: 0.6081\n",
      "Epoch [5/8], Loss: 0.5034\n",
      "Epoch [6/8], Loss: 0.4181\n",
      "Epoch [7/8], Loss: 0.3734\n",
      "Epoch [8/8], Loss: 0.3761\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.4798\n",
      "Epoch [2/8], Loss: 0.9463\n",
      "Epoch [3/8], Loss: 0.7842\n",
      "Epoch [4/8], Loss: 0.6060\n",
      "Epoch [5/8], Loss: 0.5274\n",
      "Epoch [6/8], Loss: 0.4034\n",
      "Epoch [7/8], Loss: 0.3858\n",
      "Epoch [8/8], Loss: 0.3172\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.4768\n",
      "Epoch [2/8], Loss: 1.0107\n",
      "Epoch [3/8], Loss: 0.7520\n",
      "Epoch [4/8], Loss: 0.5957\n",
      "Epoch [5/8], Loss: 0.4911\n",
      "Epoch [6/8], Loss: 0.4006\n",
      "Epoch [7/8], Loss: 0.3378\n",
      "Epoch [8/8], Loss: 0.3018\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.90      0.90      0.90       298\n",
      "       blank       0.90      1.00      0.95       200\n",
      "  haast kiwi       0.81      0.72      0.76        90\n",
      "        kaka       0.81      0.83      0.82       188\n",
      "         kea       0.94      0.87      0.90       226\n",
      "    morepork       0.92      0.93      0.92       174\n",
      "  other kiwi       0.83      0.80      0.81       308\n",
      "    shelduck       0.95      0.96      0.96       192\n",
      "    swamphen       0.88      0.93      0.90       134\n",
      "\n",
      "    accuracy                           0.88      1810\n",
      "   macro avg       0.88      0.88      0.88      1810\n",
      "weighted avg       0.88      0.88      0.88      1810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\44778\\OneDrive\\Desktop\\UWE_Docs\\7. Dissertation\\CNN Data Files\\Old_Data\\Viridis\\Mel (TSM)\"\n",
    "train_and_evaluate_AlexSGD_5fold(data_path, batch_size=16, learning_rate=0.01, num_epochs=8, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.3632\n",
      "Epoch [2/8], Loss: 0.8871\n",
      "Epoch [3/8], Loss: 0.7206\n",
      "Epoch [4/8], Loss: 0.5995\n",
      "Epoch [5/8], Loss: 0.4946\n",
      "Epoch [6/8], Loss: 0.3957\n",
      "Epoch [7/8], Loss: 0.3630\n",
      "Epoch [8/8], Loss: 0.3347\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.3866\n",
      "Epoch [2/8], Loss: 0.9245\n",
      "Epoch [3/8], Loss: 0.6734\n",
      "Epoch [4/8], Loss: 0.5369\n",
      "Epoch [5/8], Loss: 0.4408\n",
      "Epoch [6/8], Loss: 0.3749\n",
      "Epoch [7/8], Loss: 0.3529\n",
      "Epoch [8/8], Loss: 0.3480\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.3895\n",
      "Epoch [2/8], Loss: 0.8496\n",
      "Epoch [3/8], Loss: 0.6549\n",
      "Epoch [4/8], Loss: 0.5396\n",
      "Epoch [5/8], Loss: 0.4570\n",
      "Epoch [6/8], Loss: 0.3819\n",
      "Epoch [7/8], Loss: 0.3568\n",
      "Epoch [8/8], Loss: 0.3139\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.4451\n",
      "Epoch [2/8], Loss: 0.9289\n",
      "Epoch [3/8], Loss: 0.7139\n",
      "Epoch [4/8], Loss: 0.6082\n",
      "Epoch [5/8], Loss: 0.4697\n",
      "Epoch [6/8], Loss: 0.4014\n",
      "Epoch [7/8], Loss: 0.3856\n",
      "Epoch [8/8], Loss: 0.3277\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.4637\n",
      "Epoch [2/8], Loss: 0.9318\n",
      "Epoch [3/8], Loss: 0.7078\n",
      "Epoch [4/8], Loss: 0.5630\n",
      "Epoch [5/8], Loss: 0.4805\n",
      "Epoch [6/8], Loss: 0.3872\n",
      "Epoch [7/8], Loss: 0.3609\n",
      "Epoch [8/8], Loss: 0.2955\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.89      0.91      0.90       447\n",
      "       blank       0.90      0.98      0.94       300\n",
      "  haast kiwi       0.76      0.70      0.73       135\n",
      "        kaka       0.82      0.84      0.83       282\n",
      "         kea       0.95      0.88      0.91       339\n",
      "    morepork       0.98      0.95      0.97       261\n",
      "  other kiwi       0.87      0.83      0.85       462\n",
      "    shelduck       0.91      0.97      0.94       288\n",
      "    swamphen       0.81      0.85      0.83       201\n",
      "\n",
      "    accuracy                           0.89      2715\n",
      "   macro avg       0.88      0.88      0.88      2715\n",
      "weighted avg       0.89      0.89      0.89      2715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\44778\\OneDrive\\Desktop\\UWE_Docs\\7. Dissertation\\CNN Data Files\\Old_Data\\Viridis\\Mel (SSiA)\"\n",
    "train_and_evaluate_AlexSGD_5fold(data_path, batch_size=16, learning_rate=0.01, num_epochs=8, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.3051\n",
      "Epoch [2/8], Loss: 0.7810\n",
      "Epoch [3/8], Loss: 0.5672\n",
      "Epoch [4/8], Loss: 0.4413\n",
      "Epoch [5/8], Loss: 0.3901\n",
      "Epoch [6/8], Loss: 0.3170\n",
      "Epoch [7/8], Loss: 0.2830\n",
      "Epoch [8/8], Loss: 0.2463\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.2479\n",
      "Epoch [2/8], Loss: 0.7228\n",
      "Epoch [3/8], Loss: 0.5531\n",
      "Epoch [4/8], Loss: 0.4379\n",
      "Epoch [5/8], Loss: 0.3682\n",
      "Epoch [6/8], Loss: 0.3045\n",
      "Epoch [7/8], Loss: 0.2713\n",
      "Epoch [8/8], Loss: 0.2443\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.2506\n",
      "Epoch [2/8], Loss: 0.7227\n",
      "Epoch [3/8], Loss: 0.5491\n",
      "Epoch [4/8], Loss: 0.4185\n",
      "Epoch [5/8], Loss: 0.3560\n",
      "Epoch [6/8], Loss: 0.3052\n",
      "Epoch [7/8], Loss: 0.2607\n",
      "Epoch [8/8], Loss: 0.2469\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.2727\n",
      "Epoch [2/8], Loss: 0.7399\n",
      "Epoch [3/8], Loss: 0.5459\n",
      "Epoch [4/8], Loss: 0.4404\n",
      "Epoch [5/8], Loss: 0.3774\n",
      "Epoch [6/8], Loss: 0.3165\n",
      "Epoch [7/8], Loss: 0.2722\n",
      "Epoch [8/8], Loss: 0.2644\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.2732\n",
      "Epoch [2/8], Loss: 0.7391\n",
      "Epoch [3/8], Loss: 0.5535\n",
      "Epoch [4/8], Loss: 0.4501\n",
      "Epoch [5/8], Loss: 0.3565\n",
      "Epoch [6/8], Loss: 0.3057\n",
      "Epoch [7/8], Loss: 0.2427\n",
      "Epoch [8/8], Loss: 0.2372\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.90      0.91      0.91       894\n",
      "       blank       0.93      0.97      0.95       600\n",
      "  haast kiwi       0.83      0.82      0.83       270\n",
      "        kaka       0.89      0.84      0.87       564\n",
      "         kea       0.92      0.93      0.92       678\n",
      "    morepork       0.95      0.95      0.95       522\n",
      "  other kiwi       0.88      0.85      0.87       924\n",
      "    shelduck       0.93      0.97      0.95       576\n",
      "    swamphen       0.86      0.87      0.86       402\n",
      "\n",
      "    accuracy                           0.90      5430\n",
      "   macro avg       0.90      0.90      0.90      5430\n",
      "weighted avg       0.90      0.90      0.90      5430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\44778\\OneDrive\\Desktop\\UWE_Docs\\7. Dissertation\\CNN Data Files\\Old_Data\\Viridis\\Mel (TSM + SSiA)\"\n",
    "train_and_evaluate_AlexSGD_5fold(data_path, batch_size=16, learning_rate=0.01, num_epochs=8, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.0881\n",
      "Epoch [2/8], Loss: 0.4682\n",
      "Epoch [3/8], Loss: 0.2887\n",
      "Epoch [4/8], Loss: 0.1956\n",
      "Epoch [5/8], Loss: 0.1475\n",
      "Epoch [6/8], Loss: 0.1111\n",
      "Epoch [7/8], Loss: 0.0922\n",
      "Epoch [8/8], Loss: 0.0718\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.2328\n",
      "Epoch [2/8], Loss: 0.5983\n",
      "Epoch [3/8], Loss: 0.3728\n",
      "Epoch [4/8], Loss: 0.2645\n",
      "Epoch [5/8], Loss: 0.1924\n",
      "Epoch [6/8], Loss: 0.1524\n",
      "Epoch [7/8], Loss: 0.1125\n",
      "Epoch [8/8], Loss: 0.0919\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.2999\n",
      "Epoch [2/8], Loss: 0.5693\n",
      "Epoch [3/8], Loss: 0.3421\n",
      "Epoch [4/8], Loss: 0.2270\n",
      "Epoch [5/8], Loss: 0.1682\n",
      "Epoch [6/8], Loss: 0.1314\n",
      "Epoch [7/8], Loss: 0.1000\n",
      "Epoch [8/8], Loss: 0.0757\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.2690\n",
      "Epoch [2/8], Loss: 0.6021\n",
      "Epoch [3/8], Loss: 0.3737\n",
      "Epoch [4/8], Loss: 0.2534\n",
      "Epoch [5/8], Loss: 0.1983\n",
      "Epoch [6/8], Loss: 0.1437\n",
      "Epoch [7/8], Loss: 0.1338\n",
      "Epoch [8/8], Loss: 0.1066\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.3588\n",
      "Epoch [2/8], Loss: 0.7590\n",
      "Epoch [3/8], Loss: 0.5417\n",
      "Epoch [4/8], Loss: 0.3982\n",
      "Epoch [5/8], Loss: 0.3083\n",
      "Epoch [6/8], Loss: 0.2438\n",
      "Epoch [7/8], Loss: 0.2008\n",
      "Epoch [8/8], Loss: 0.1588\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.93      0.97      0.95       894\n",
      "       blank       0.95      0.98      0.96       600\n",
      "  haast kiwi       0.87      0.84      0.85       270\n",
      "        kaka       0.94      0.92      0.93       564\n",
      "         kea       0.96      0.95      0.96       678\n",
      "    morepork       0.98      0.98      0.98       522\n",
      "  other kiwi       0.94      0.91      0.93       924\n",
      "    shelduck       0.96      0.98      0.97       576\n",
      "    swamphen       0.95      0.93      0.94       402\n",
      "\n",
      "    accuracy                           0.95      5430\n",
      "   macro avg       0.94      0.94      0.94      5430\n",
      "weighted avg       0.95      0.95      0.95      5430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_AlexAdaGrad_5fold(data_path, batch_size=16, learning_rate=0.001, num_epochs=8, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\44778\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 1.0951\n",
      "Epoch [2/8], Loss: 0.5032\n",
      "Epoch [3/8], Loss: 0.3356\n",
      "Epoch [4/8], Loss: 0.2684\n",
      "Epoch [5/8], Loss: 0.2095\n",
      "Epoch [6/8], Loss: 0.1668\n",
      "Epoch [7/8], Loss: 0.1593\n",
      "Epoch [8/8], Loss: 0.1122\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.0161\n",
      "Epoch [2/8], Loss: 0.5122\n",
      "Epoch [3/8], Loss: 0.3304\n",
      "Epoch [4/8], Loss: 0.2677\n",
      "Epoch [5/8], Loss: 0.2361\n",
      "Epoch [6/8], Loss: 0.1765\n",
      "Epoch [7/8], Loss: 0.1725\n",
      "Epoch [8/8], Loss: 0.1509\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 0.9841\n",
      "Epoch [2/8], Loss: 0.4926\n",
      "Epoch [3/8], Loss: 0.3369\n",
      "Epoch [4/8], Loss: 0.2514\n",
      "Epoch [5/8], Loss: 0.2221\n",
      "Epoch [6/8], Loss: 0.1650\n",
      "Epoch [7/8], Loss: 0.1665\n",
      "Epoch [8/8], Loss: 0.1338\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 1.0268\n",
      "Epoch [2/8], Loss: 0.4965\n",
      "Epoch [3/8], Loss: 0.3326\n",
      "Epoch [4/8], Loss: 0.2565\n",
      "Epoch [5/8], Loss: 0.2302\n",
      "Epoch [6/8], Loss: 0.1855\n",
      "Epoch [7/8], Loss: 0.1417\n",
      "Epoch [8/8], Loss: 0.1482\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [1/8], Loss: 0.9688\n",
      "Epoch [2/8], Loss: 0.4575\n",
      "Epoch [3/8], Loss: 0.3295\n",
      "Epoch [4/8], Loss: 0.2682\n",
      "Epoch [5/8], Loss: 0.2041\n",
      "Epoch [6/8], Loss: 0.2032\n",
      "Epoch [7/8], Loss: 0.1568\n",
      "Epoch [8/8], Loss: 0.1174\n",
      "--------------------------------\n",
      "Final Cross-Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bellbird       0.92      0.96      0.94       894\n",
      "       blank       0.94      0.96      0.95       600\n",
      "  haast kiwi       0.85      0.79      0.82       270\n",
      "        kaka       0.90      0.92      0.91       564\n",
      "         kea       0.98      0.95      0.96       678\n",
      "    morepork       0.97      0.97      0.97       522\n",
      "  other kiwi       0.92      0.89      0.90       924\n",
      "    shelduck       0.97      0.97      0.97       576\n",
      "    swamphen       0.91      0.91      0.91       402\n",
      "\n",
      "    accuracy                           0.93      5430\n",
      "   macro avg       0.93      0.92      0.93      5430\n",
      "weighted avg       0.93      0.93      0.93      5430\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_and_evaluate_AlexAdam_5fold(data_path, batch_size=16, learning_rate=0.0001, num_epochs=8, num_folds=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
